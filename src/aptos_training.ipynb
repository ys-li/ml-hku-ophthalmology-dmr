{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"aptos_training.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"k3J3YYjOx3ce"},"source":["### Set up environment"]},{"cell_type":"code","metadata":{"id":"Hlgc8VmQw0oJ"},"source":["# efficientnet-b0-224\n","# efficientnet-b1-240\n","# efficientnet-b2-260\n","# efficientnet-b3-300\n","# efficientnet-b4-380\n","# efficientnet-b5-456\n","# efficientnet-b6-528\n","# efficientnet-b7-600"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tq_g_7P1y_xg"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","print(gpu_info)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!ln -s /content/drive/My\\ Drive/Colab\\ Notebooks/hku-oph/* /content/\n","%cd /content/src"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"hidden":true,"id":"_Esa4Q1gx3cf"},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","        \n","# ML libraries required\n","from fastai import *\n","from fastai.vision import *\n","from fastai.callbacks import *\n","from fastai.metrics import KappaScore # solution evaluated with qudratic kappa\n","from fastai.tabular import * # for ensemble model training\n","import torch\n","# efficientnet is not integrated into fastai yet\n","\n","\n","# Other libraries required\n","import matplotlib.pyplot as plt\n","from models.efficientnet_pytorch import EfficientNet\n","\n","# garbage collector\n","import gc\n","\n","import random\n","from datetime import datetime\n","\n","def seed_everything(seed_value, use_cuda=True):\n","    os.environ['PYTHONHASHSEED'] = str(seed_value)\n","    np.random.seed(seed_value) # cpu vars\n","    torch.manual_seed(seed_value) # cpu  vars\n","    random.seed(seed_value) # Python\n","    if use_cuda: \n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\n","        torch.backends.cudnn.deterministic = True  #needed\n","        torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(42, True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"_9Bkv6oHx3ci"},"source":["### Define model details"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-05-13T17:46:27.239529Z","start_time":"2020-05-13T17:46:27.236883Z"},"hidden":true,"id":"mmbIu9tCx3ci"},"source":["import json\n","models_config = {}\n","only_train_model = None\n","with open('models_config.json') as f:\n","    models_config = json.load(f)\n","    meta_config = models_config[\"meta\"]\n","    ensemble_config = models_config[\"ensemble\"]\n","    models_config = models_config[\"models\"]\n","    \n","if \"only_train_model\" in meta_config:\n","    only_train_model = meta_config[\"only_train_model\"]\n","\n","only_train_model = \"effnet-b5\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"ZMUQC6ppx3cl"},"source":["### Import preprocessing modules"]},{"cell_type":"code","metadata":{"hidden":true,"id":"vqKY1H0lx3cl"},"source":["%run preprocessing.ipynb\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"phGFqWF1x3co"},"source":["### Load data"]},{"cell_type":"code","metadata":{"hidden":true,"id":"PXODfy6Bx3cp"},"source":["class PreProcessCommonWrapper(object):\n","    def __init__(self, image_dim):\n","        self.image_dim = image_dim\n","        self.__name__ = \"PreProcessCommonWrapper\"\n","        self.__annotations__ = {}\n","    def __call__(self, t): # the function formerly known as \"bar\"\n","        return contrast_and_crop(t, self.image_dim)\n","\n","def load_data(model_config):\n","    current_model_config = model_config\n","    print(current_model_config)\n","    base19_dir = os.path.join('../', 'input/aptos_image/')\n","    train19_dir = os.path.join('../', 'input/aptos_image/train_19/')\n","    base15_dir = os.path.join('../', 'input/aptos_image/')\n","    train15_dir = os.path.join('../', 'input/aptos_image/train_15/')\n","    \n","    df = pd.read_csv(os.path.join(base19_dir, 'labels/trainLabels19.csv'))\n","    \n","    df15 = pd.read_csv(os.path.join(base15_dir, 'labels/trainLabels15.csv'))\n","    \n","    # change id_code to accessible path and drops the id_code col\n","    df['path'] = df['file_name'].map(lambda x: os.path.join(train19_dir,f'{x}.jpg'))\n","    df = df.drop(columns=['file_name'])\n","    df15['path'] = df15['file_name'].map(lambda x: os.path.join(train15_dir,f'{x}.jpg'))\n","    df15 = df15.drop(columns=['file_name'])\n","    \n","    # add extras to training set\n","    df = pd.concat([df,df15], ignore_index=True)\n","    \n","    src = ImageList.from_df(df=df, path = './', cols='path') \\\n","                   .split_by_rand_pct(seed=42) \\\n","                   .label_from_df(cols='diagnosis', label_cls=FloatList)  # although labels are in integer form, they are intepreted as Float for training purposes\n","            \n","    transformations = get_transforms(do_flip=True,flip_vert=True,max_rotate=360,max_warp=0,max_zoom=1.3,max_lighting=0.1,p_lighting=0.5)\n","    \n","    # custom pre-processing (contrast and crop)\n","    pre_process_common_wrapper = PreProcessCommonWrapper(model_config[\"image_dim\"])\n","    pre_process_ccs = [TfmPixel(pre_process_common_wrapper)()]\n","    advprop = model_config[\"advprop\"]\n","    if advprop:\n","        pre_process_ccs.append(TfmPixel(advprop_normalise)())\n","    # apply transformations to training set, but apply the pre_process to train and valid set\n","    tfms = [transformations[0] + pre_process_ccs, transformations[1] + pre_process_ccs]\n","    \n","    # transform data sets\n","    data = src.transform(tfms, size=model_config[\"image_dim\"], resize_method=ResizeMethod.CROP,padding_mode='zeros',) \\\n","              .databunch(bs=model_config[\"batch_size\"], num_workers=1) \\\n","              .normalize(imagenet_stats if not advprop else None) # default normalise with imagenet stats, prebuilt into fast.ai library    \n","    \n","    print(\"loaded data\")\n","    return (df, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"hidden":true,"id":"LjMN7z0zx3cr"},"source":["# lets visualise what we have got\n","import warnings \n","warnings.filterwarnings(\"ignore\")\n","# df, data = load_data(models_config[\"effnet-b3\"])\n","# data.show_batch(rows=3, figsize=(10,10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LREafLPlx3cu"},"source":["### Helper functions in loading models"]},{"cell_type":"code","metadata":{"id":"txTn7hH5x3cv"},"source":["def getModel(model_name, data, model_dir=None, advprop=False, **kwargs):\n","    from os.path import abspath\n","    if model_dir is not None:\n","        model_dir = abspath(model_dir)\n","    model = EfficientNet.from_pretrained(model_name, advprop=advprop)\n","    model._fc = nn.Linear(model._fc.in_features,data.c) # .c returns number of output cells, ._fc returns the module\n","    return model\n","\n","def get_learner(model_name, data, model_dir=\"models/\", advprop=False):\n","    return Learner(data, getModel(model_name, data, model_dir=model_dir, advprop=advprop), metrics = [quadratic_kappa]) \\\n","           .mixup() \\\n","           .to_fp16() \n","\n","# quadratic kappa score\n","from sklearn.metrics import cohen_kappa_score\n","def quadratic_kappa(y_hat, y):\n","    y_hat = y_hat.cpu()\n","    y = y.cpu()\n","    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fux1ofMwx3cy"},"source":["### Train main models routine"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-05-17T13:11:11.518309Z","start_time":"2020-05-17T13:11:11.510659Z"},"id":"PppYkPEwx3cz"},"source":["valid_predictions = {}\n","valid_labels = []\n","\n","def train_nets():\n","    for config_name in models_config:\n","\n","        if only_train_model and only_train_model != config_name:\n","            print(f\"---- TRAINING SKIPPED FOR {config_name} ---\")\n","            continue # skip this model\n","            # only train one model\n","            \n","        print(f\"---- TRAINING STARTING FOR {config_name} ---\")\n","        config = models_config[config_name]\n","        df, data = load_data(config)\n","        learner = get_learner(config[\"pretrained_name\"], data, model_dir=config[\"pretrained_path\"], advprop=config[\"advprop\"])\n","        lr = config[\"lr\"]\n","        # learner.lr_find()\n","        # learner.recorder.plot()\n","        # break\n","\n","        # try to get the previous epochs, if any\n","        path = config[\"pretrained_path\"]\n","        onlyfiles = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n","        start_epoch = None\n","        for fn in onlyfiles:\n","            temp = fn.replace('.pth', '').split('_')\n","            if temp[0] == config_name and temp[1] == 'e':\n","                if start_epoch is None or int(temp[2]) > start_epoch:\n","                    start_epoch = int(temp[2])\n","        if start_epoch is not None:\n","            start_epoch += 1\n","        \n","        # training starts here \n","        learner.fit_one_cycle(\n","            config[\"epoch_n\"], \n","            lr,\n","            start_epoch=start_epoch,\n","            callbacks=[\n","                SaveModelCallback(learner, every='epoch', monitor='valid_loss', name=f'{config_name}_e'),\n","                # SaveModelCallback(learner, every='improvement', monitor='valid_loss', name=f'{config_name}_best')\n","            ]\n","        )\n","        # learner.save(f'{config_name}_{int(datetime.now().timestamp())}')\n","        \n","        # perform prediction on \n","        valid_predictions[config_name], valid_labels = learner.get_preds(DatasetType.Valid)\n","        valid_predictions[config_name] = valid_predictions[config_name].flatten().tolist()\n","        del learner\n","        # gc.collect()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kp1h0hBTx3c1"},"source":["### Ensemble layer"]},{"cell_type":"code","metadata":{"id":"kE6bQ_dnx3c2"},"source":["def train_ensemble_average():\n","    valid_predictions[\"diagnosis\"] = valid_labels\n","    valid_df = pd.DataFrame(valid_predictions)\n","    procs = [Normalize]\n","    ensemble_bunch = TabularList.from_df(df=valid_df, cont_names=model_names, procs=procs) \\\n","                                .split_by_rand_pct() \\\n","                                .label_from_df(cols='diagnosis') \\\n","                                .databunch()\n","    \n","    learner = tabular_learner(ensemble_bunch, layers=[100, 50], ps=[0.4,0.2], metrics=[quadratic_kappa]) \n","    # learner.lr_find()\n","    # learner.recorder.plot()\n","    lr = ensemble_config[\"lr\"]\n","    epoch_n = ensemble_config[\"epoch_n\"]\n","    learner.fit_one_cycle(\n","        epoch_n, \n","        lr, \n","        callbacks=[SaveModelCallback(learner, every='improvement', monitor='valid_loss', name=\"ensemble\")]\n","    )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R22wlMCRx3c4"},"source":["### Entrypoint"]},{"cell_type":"code","metadata":{"id":"DbwQAyzux3c4"},"source":["if __name__ == '__main__':\n","    import warnings \n","    warnings.filterwarnings(\"ignore\")\n","    train_nets()\n","    train_ensemble_average()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pItq7CG-snsr"},"source":["%ls ./../input/aptos_image/train_15/"],"execution_count":null,"outputs":[]}]}